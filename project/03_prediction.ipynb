{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_classifier_df_to_csv(df: pd.DataFrame, filename: str):\n",
    "    df.to_csv(\"../data/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare new data for hypothesis testing\n",
    "def add_to_classifier_df(df, classifier_name, prediction_results):\n",
    "    df[classifier_name] = np.array(prediction_results)\n",
    "\n",
    "def export_classifier_to_df(classifier_dataframe: pd.DataFrame, name: str):\n",
    "    classifier_dataframe.to_csv('../data/' + name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 1: Try to predict rank directly (from viral 50 -> top 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_viral</th>\n",
       "      <th>viral_50_rank</th>\n",
       "      <th>date_top200</th>\n",
       "      <th>top_200_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10463</th>\n",
       "      <td>love nwantiti (ah ah ah)</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>The Box</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>Head &amp; Heart (feat. MNEK)</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>Way Out (feat. Big Sean)</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>Please Don't Go</td>\n",
       "      <td>2021-03-21</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>ROXANNE</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>telepatía</td>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>Somebody's Watching Me</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8182</th>\n",
       "      <td>Ramen &amp; OJ</td>\n",
       "      <td>2021-06-05</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  date_viral  viral_50_rank date_top200  \\\n",
       "10463   love nwantiti (ah ah ah)  2021-11-01           33.0  2021-11-02   \n",
       "1278                     The Box  2020-02-29           23.0  2020-03-01   \n",
       "4127   Head & Heart (feat. MNEK)  2020-08-22           14.0  2020-08-23   \n",
       "5882    Way Out (feat. Big Sean)  2021-01-04           32.0  2021-01-05   \n",
       "7002             Please Don't Go  2021-03-21           33.0  2021-03-22   \n",
       "403                      ROXANNE  2020-01-15           26.0  2020-01-16   \n",
       "7377                   telepatía  2021-04-13           36.0  2021-04-14   \n",
       "10401     Somebody's Watching Me  2021-10-29           21.0  2021-10-30   \n",
       "8182                  Ramen & OJ  2021-06-05           40.0  2021-06-06   \n",
       "2031                    Skechers  2020-04-05            1.0  2020-04-06   \n",
       "\n",
       "       top_200_rank  \n",
       "10463          32.0  \n",
       "1278            1.0  \n",
       "4127          107.0  \n",
       "5882           23.0  \n",
       "7002           93.0  \n",
       "403             3.0  \n",
       "7377           14.0  \n",
       "10401         131.0  \n",
       "8182           89.0  \n",
       "2031           69.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_ranks = pd.read_csv(\"../data/weekly_ranks.csv\")\n",
    "avg_ranks.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "avg_ranks.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier_approach_1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(avg_ranks[\"viral_50_rank\"].values,avg_ranks[\"top_200_rank\"].values, train_size=0.8)\n",
    "xtrain = xtrain.reshape(-1,1)\n",
    "xtest = xtest.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add truth values to dataframe\n",
    "add_to_classifier_df(df_classifier_approach_1, 'truth', ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with svm\n",
    "svm_linear = SVC(kernel='linear')\n",
    "\n",
    "svm_fit_linear = svm_linear.fit(xtrain, ytrain)\n",
    "ypred = svm_fit_linear.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector machines with linear kernel is: 0.028684907325684024\n",
      "r^2 score of support vector machines with linear kernel is: 0.029687672442335285\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of support vector machines with linear kernel is: {accuracy_score(ypred, ytest)}')\n",
    "print(f'r^2 score of support vector machines with linear kernel is: {svm_fit_linear.score(xtrain, ytrain)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel='poly')\n",
    "\n",
    "svm_fit_poly = svm_poly.fit(xtrain, ytrain)\n",
    "ypred = svm_fit_poly.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector machines with polynomial kernel is: 0.02912621359223301\n",
      "r^2 score of support vector machines with polynomial kernel is: 0.029908398631497628\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of support vector machines with polynomial kernel is: {accuracy_score(ypred, ytest)}')\n",
    "print(f'r^2 score of support vector machines with polynomial kernel is: {svm_fit_poly.score(xtrain, ytrain)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_degree = 3\n",
    "polyn_reg = make_pipeline(PolynomialFeatures(poly_degree),LinearRegression()) # create polynomial regression model\n",
    "\n",
    "polyn_reg = polyn_reg.fit(xtrain, ytrain)\n",
    "ypred = polyn_reg.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002598725700015181"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyn_reg.score(xtrain,ytrain)# R² score for training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPROACH 2: Try with trend and viral 50 to predict top 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_viral</th>\n",
       "      <th>viral_50_rank</th>\n",
       "      <th>date_top200</th>\n",
       "      <th>top_200_rank</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>97.0</td>\n",
       "      <td>SAME_POSITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Sunday Best</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9886</th>\n",
       "      <td>Happier Than Ever - Edit</td>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>102.0</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11326</th>\n",
       "      <td>abcdefu</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MOVE_DOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>INDUSTRY BABY (feat. Jack Harlow)</td>\n",
       "      <td>2021-08-22</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SAME_POSITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10629</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>55.0</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>Sunday Best</td>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>17.0</td>\n",
       "      <td>MOVE_DOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>WITHOUT YOU</td>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>Ruff Ryders' Anthem</td>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-04-11</td>\n",
       "      <td>35.0</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Suicidal</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>SAME_POSITION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  date_viral  viral_50_rank  \\\n",
       "1854                            Skechers  2020-03-29            1.0   \n",
       "1022                         Sunday Best  2020-02-14           22.0   \n",
       "9886            Happier Than Ever - Edit  2021-09-29           46.0   \n",
       "11326                            abcdefu  2021-12-30           18.0   \n",
       "9313   INDUSTRY BABY (feat. Jack Harlow)  2021-08-22           23.0   \n",
       "10629                              Toxic  2021-11-10           19.0   \n",
       "2769                         Sunday Best  2020-05-24           48.0   \n",
       "6071                         WITHOUT YOU  2021-01-19           48.0   \n",
       "7330                 Ruff Ryders' Anthem  2021-04-10            4.0   \n",
       "23                              Suicidal  2020-01-01           11.0   \n",
       "\n",
       "      date_top200  top_200_rank          trend  \n",
       "1854   2020-03-30          97.0  SAME_POSITION  \n",
       "1022   2020-02-15          65.0        MOVE_UP  \n",
       "9886   2021-09-30         102.0        MOVE_UP  \n",
       "11326  2021-12-31           5.0      MOVE_DOWN  \n",
       "9313   2021-08-23           2.0  SAME_POSITION  \n",
       "10629  2021-11-11          55.0        MOVE_UP  \n",
       "2769   2020-05-25          17.0      MOVE_DOWN  \n",
       "6071   2021-01-20           7.0        MOVE_UP  \n",
       "7330   2021-04-11          35.0        MOVE_UP  \n",
       "23     2020-01-02          12.0  SAME_POSITION  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ranks_with_trend = pd.read_csv(\"../data/weekly_ranks_with_trends.csv\")\n",
    "avg_ranks_with_trend.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "avg_ranks_with_trend.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare new data for hypothesis testing\n",
    "def add_to_classifier_df(df, classifier_name, prediction_results):\n",
    "    df[classifier_name] = np.array(prediction_results)\n",
    "\n",
    "def export_classifier_to_df(classifier_dataframe: pd.DataFrame, name: str):\n",
    "    classifier_dataframe.to_csv('../data/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier_approach_2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(avg_ranks_with_trend[[\"viral_50_rank\", \"trend\"]], avg_ranks_with_trend[\"top_200_rank\"], train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add truth values to dataframe\n",
    "add_to_classifier_df(df_classifier_approach_2, 'truth', ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = Pipeline([('ohe', OneHotEncoder()), ('clf', SVC(kernel='linear'))])\n",
    "\n",
    "svm_fit_linear = svm_linear.fit(xtrain, ytrain)\n",
    "ypred = svm_fit_linear.predict(xtest)\n",
    "\n",
    "# add to classifier dataframe\n",
    "add_to_classifier_df(df_classifier_approach_2, 'SVC_linear', ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector machines with linear kernel is: 0.019858781994704325\n",
      "r^2 score of support vector machines with linear kernel is: 0.04602141044034875\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of support vector machines with linear kernel is: {accuracy_score(ypred, ytest)}')\n",
    "print(f'r^2 score of support vector machines with linear kernel is: {svm_fit_linear.score(xtrain, ytrain)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_poly = Pipeline([('ohe', OneHotEncoder()), ('clf', SVC(kernel='rbf'))])\n",
    "\n",
    "svm_fit_poly = svm_linear_poly.fit(xtrain, ytrain)\n",
    "ypred = svm_fit_poly.predict(xtest)\n",
    "\n",
    "# add to classifier dataframe\n",
    "add_to_classifier_df(df_classifier_approach_2, 'SVC_rbf', ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector machines with polynomial kernel is: 0.02471315092674316\n",
      "r^2 score of support vector machines with polynomial kernel is: 0.058050987749696505\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of support vector machines with polynomial kernel is: {accuracy_score(ypred, ytest)}')\n",
    "print(f'r^2 score of support vector machines with polynomial kernel is: {svm_fit_poly.score(xtrain, ytrain)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 3: Try to predict trend of top 200 charts from viral chart position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_freq_for_classification(freq):\n",
    "    if freq == 1:\n",
    "        return pd.read_csv('../data/daily_ranks_with_trends_top_200.csv')\n",
    "    elif freq == 3:\n",
    "        return pd.read_csv('../data/3_days_ranks_with_trends_top_200.csv')\n",
    "    elif freq == 7:\n",
    "        return pd.read_csv('../data/weekly_ranks_with_trends_top_200.csv')\n",
    "    else:\n",
    "        print('Wrong input, taking weekly granularity!')\n",
    "        return pd.read_csv('../data/weekly_ranks_with_trends_top_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>date_viral</th>\n",
       "      <th>viral_50_rank</th>\n",
       "      <th>date_top200</th>\n",
       "      <th>top_200_rank</th>\n",
       "      <th>trend_top_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adore You</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>18</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>All I Want - From \"High School Musical: The Mu...</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>66</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ayy Macarena</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>20</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>143</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ballin' (with Roddy Ricch)</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>38</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>13</td>\n",
       "      <td>SAME_POSITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>12</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>15</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>9</td>\n",
       "      <td>SAD GIRLZ LUV MONEY Remix (feat. Kali Uchis an...</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>47</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>166</td>\n",
       "      <td>NEW_ENTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>10</td>\n",
       "      <td>Super Gremlin</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>6</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>11</td>\n",
       "      <td>Surface Pressure</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>62</td>\n",
       "      <td>NEW_ENTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>12</td>\n",
       "      <td>We Don't Talk About Bruno</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>27</td>\n",
       "      <td>NEW_ENTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>13</td>\n",
       "      <td>abcdefu</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>8</td>\n",
       "      <td>MOVE_UP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1546 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "0              0                                          Adore You   \n",
       "1              1  All I Want - From \"High School Musical: The Mu...   \n",
       "2              2                                       Ayy Macarena   \n",
       "3              3                         Ballin' (with Roddy Ricch)   \n",
       "4              4                                    Blinding Lights   \n",
       "...          ...                                                ...   \n",
       "1541           9  SAD GIRLZ LUV MONEY Remix (feat. Kali Uchis an...   \n",
       "1542          10                                      Super Gremlin   \n",
       "1543          11                                   Surface Pressure   \n",
       "1544          12                          We Don't Talk About Bruno   \n",
       "1545          13                                            abcdefu   \n",
       "\n",
       "      date_viral  viral_50_rank date_top200  top_200_rank  trend_top_200  \n",
       "0     2020-01-05             10  2020-01-12            18        MOVE_UP  \n",
       "1     2020-01-05              2  2020-01-12            66        MOVE_UP  \n",
       "2     2020-01-05             20  2020-01-12           143        MOVE_UP  \n",
       "3     2020-01-05             38  2020-01-12            13  SAME_POSITION  \n",
       "4     2020-01-05             12  2020-01-12            15        MOVE_UP  \n",
       "...          ...            ...         ...           ...            ...  \n",
       "1541  2021-12-19             47  2021-12-26           166      NEW_ENTRY  \n",
       "1542  2021-12-19             23  2021-12-26             6        MOVE_UP  \n",
       "1543  2021-12-19              6  2021-12-26            62      NEW_ENTRY  \n",
       "1544  2021-12-19              1  2021-12-26            27      NEW_ENTRY  \n",
       "1545  2021-12-19              4  2021-12-26             8        MOVE_UP  \n",
       "\n",
       "[1546 rows x 7 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trends_top_200 = choose_freq_for_classification(7)\n",
    "df_trends_top_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier_approach_3 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_3, xtest_3, ytrain_3, ytest_3 = train_test_split(df_trends_top_200[[\"viral_50_rank\"]], df_trends_top_200[\"trend_top_200\"], train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add truth value for test classifier results\n",
    "add_to_classifier_df(df_classifier_approach_3, 'truth', ytest_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(kernel='linear')\n",
    "\n",
    "svm_fit_linear = svm_linear.fit(xtrain_3, ytrain_3)\n",
    "ypred_svm_linear = svm_fit_linear.predict(xtest_3)\n",
    "\n",
    "add_to_classifier_df(df_classifier_approach_3, 'svm_linear', ypred_svm_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector machines with linear kernel is: 0.5806451612903226\n",
      "r^2 score of support vector machines with linear kernel is: 0.5266990291262136\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of support vector machines with linear kernel is: {accuracy_score(ypred_svm_linear, ytest_3)}')\n",
    "print(f'r^2 score of support vector machines with linear kernel is: {svm_fit_linear.score(xtrain_3, ytrain_3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly= SVC(kernel='poly', degree=3)\n",
    "\n",
    "svm_fit_poly = svm_poly.fit(xtrain_3, ytrain_3)\n",
    "ypred_svm_poly = svm_fit_poly.predict(xtest_3)\n",
    "\n",
    "add_to_classifier_df(df_classifier_approach_3, 'svm_poly', ypred_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector machines with poly kernel is: 0.5806451612903226\n",
      "r^2 score of support vector machines with poly kernel is: 0.5266990291262136\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of support vector machines with poly kernel is: {accuracy_score(ypred_svm_poly, ytest_3)}')\n",
    "print(f'r^2 score of support vector machines with poly kernel is: {svm_fit_poly.score(xtrain_3, ytrain_3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg_fit = log_reg.fit(xtrain_3, ytrain_3)\n",
    "ypred_log_reg = log_reg_fit.predict(xtest_3)\n",
    "\n",
    "add_to_classifier_df(df_classifier_approach_3, 'logistic_regression', ypred_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector machines with linear kernel is: 0.5806451612903226\n",
      "r^2 score of support vector machines with linear kernel is: 0.5266990291262136\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of support vector machines with linear kernel is: {accuracy_score(ypred_log_reg, ytest_3)}')\n",
    "print(f'r^2 score of support vector machines with linear kernel is: {log_reg_fit.score(xtrain_3, ytrain_3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_fit = knn.fit(xtrain_3, ytrain_3)\n",
    "ypred_knn = knn_fit.predict(xtest_3)\n",
    "\n",
    "add_to_classifier_df(df_classifier_approach_3, 'k_nearest_neighbour', ypred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of knn is: 0.45806451612903226\n",
      "r^2 score of knn is: 0.45145631067961167\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy of knn is: {accuracy_score(ypred_knn, ytest_3)}')\n",
    "print(f'r^2 score of knn is: {knn_fit.score(xtrain_3, ytrain_3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_classifier_df_to_csv(df_classifier_approach_3, \"classification_results_approach_3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science-5TF-S9g6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91c9c3035d31b1b248a09f4683e22d2eee92d43933c62df06aa9c8e048bab2cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
