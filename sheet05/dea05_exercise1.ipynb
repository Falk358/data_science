{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as pyplot\n",
    "import json\n",
    "from sklearn import feature_extraction as fe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the texts and source site from the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_txt</th>\n",
       "      <th>problem_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>The authors of the book mentioned that problem...</td>\n",
       "      <td>linguistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>I'd second TopinFrassi's answer, that this is ...</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>Yes, because Steve Pearce became the first pla...</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>If you feel any form of discomfort when you st...</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>which is sometimes used for 26\" -&gt; 700c conver...</td>\n",
       "      <td>mathoverflow.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>(emphasis mine) Is there a real \"Western novel...</td>\n",
       "      <td>workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>I'm writing a story, based vaguely off of the ...</td>\n",
       "      <td>linguistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>The spacing between 9 speed and 10 speed is co...</td>\n",
       "      <td>buddhism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>As for your example, is there a reason that bo...</td>\n",
       "      <td>workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>To simplify, if you find this account of B-the...</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            problem_txt      problem_site\n",
       "2489  The authors of the book mentioned that problem...       linguistics\n",
       "2192  I'd second TopinFrassi's answer, that this is ...        philosophy\n",
       "3533  Yes, because Steve Pearce became the first pla...         astronomy\n",
       "3192  If you feel any form of discomfort when you st...        philosophy\n",
       "7975  which is sometimes used for 26\" -> 700c conver...  mathoverflow.net\n",
       "5999  (emphasis mine) Is there a real \"Western novel...         workplace\n",
       "7057  I'm writing a story, based vaguely off of the ...       linguistics\n",
       "4513  The spacing between 9 speed and 10 speed is co...          buddhism\n",
       "5170  As for your example, is there a reason that bo...         workplace\n",
       "4995  To simplify, if you find this account of B-the...        philosophy"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = \"../data/pan\"\n",
    "txt_files = glob.glob(\"problem-*.txt\", root_dir = dir_path)\n",
    "json_files = glob.glob(\"truth-problem-*.json\", root_dir=dir_path)\n",
    "\n",
    "buffer_dict = []\n",
    "for (txt_path, json_path) in zip(txt_files,json_files): # read all files and concatenate the relevant content into a dictionary\n",
    "    txt_path = dir_path + \"/\" + txt_path\n",
    "    json_path = dir_path + \"/\" + json_path\n",
    "    with open(json_path) as json_f:\n",
    "        json_dict = json.load(json_f)\n",
    "        with open(txt_path) as txt_f:\n",
    "            txt_content = txt_f.read()\n",
    "            d= {\n",
    "                \"problem_txt\": txt_content,\n",
    "                \"problem_site\": json_dict[\"site\"]\n",
    "            }\n",
    "            buffer_dict.append(d)\n",
    "\n",
    "\n",
    "\n",
    "raw_df = pd.DataFrame(buffer_dict)\n",
    "raw_df.sample(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute our ngrams with sklearn countVectorizer (ex 1b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = fe.text.CountVectorizer(ngram_range=(1,3))\n",
    "mat = vec.fit_transform(raw_df[\"problem_txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An n gram means that we pick out n words at a time for our bag of words model; *Bag of words* refers to a vector notation were we count the occurences for each  possible word (or gram) in our input text. Bag of words notation is very sparse, since most entries are 0 count entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we obtained the matrix, lets sum up the entries so we can see which ngrams are most common in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 897318), ('to', 489344), ('of', 416040), ('and', 352429), ('is', 332516), ('in', 278562), ('you', 260670), ('that', 259713), ('it', 227093), ('for', 159859), ('be', 150638), ('this', 141588), ('are', 127193), ('as', 124347), ('not', 114423), ('on', 114005), ('with', 108662), ('if', 108404), ('have', 103015), ('or', 99420), ('can', 96762), ('your', 94317), ('but', 93846), ('of the', 88540), ('an', 71277)]\n"
     ]
    }
   ],
   "source": [
    "summed_grams = mat.sum(axis=0)\n",
    "words_freq = [(word, summed_grams[0,i]) for word, i in vec.vocabulary_.items()] # get an indexed list where each ngram is key and count of that ngram is val\n",
    "words_freq = sorted(words_freq, key= lambda x: x[1], reverse=True)\n",
    "print(words_freq[:25])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('data_science-dDCtDHdq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "879e0aa37acc94d6458fa173f3288bcea56e82a3b9fca582a9c7d294b714e537"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
