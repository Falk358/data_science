{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20968</th>\n",
       "      <td>Contemporary machine learning: a guide for pra...</td>\n",
       "      <td>Machine learning is finding increasingly bro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20969</th>\n",
       "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
       "      <td>Polycrystalline diamond coatings have been g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20970</th>\n",
       "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
       "      <td>We present a new approach for identifying si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971</th>\n",
       "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
       "      <td>The sum of Log-normal variates is encountere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>Why optional stopping is a problem for Bayesians</td>\n",
       "      <td>Recently, optional stopping has been a subje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20972 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TITLE  \\\n",
       "ID                                                         \n",
       "1            Reconstructing Subject-Specific Effect Maps   \n",
       "2                     Rotation Invariance Neural Network   \n",
       "3      Spherical polyharmonics and Poisson kernels fo...   \n",
       "4      A finite element approximation for the stochas...   \n",
       "5      Comparative study of Discrete Wavelet Transfor...   \n",
       "...                                                  ...   \n",
       "20968  Contemporary machine learning: a guide for pra...   \n",
       "20969  Uniform diamond coatings on WC-Co hard alloy c...   \n",
       "20970  Analysing Soccer Games with Clustering and Con...   \n",
       "20971  On the Efficient Simulation of the Left-Tail o...   \n",
       "20972   Why optional stopping is a problem for Bayesians   \n",
       "\n",
       "                                                ABSTRACT  Computer Science  \\\n",
       "ID                                                                           \n",
       "1        Predictive models allow subject-specific inf...                 1   \n",
       "2        Rotation invariance and translation invarian...                 1   \n",
       "3        We introduce and develop the notion of spher...                 0   \n",
       "4        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "5        Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "...                                                  ...               ...   \n",
       "20968    Machine learning is finding increasingly bro...                 1   \n",
       "20969    Polycrystalline diamond coatings have been g...                 0   \n",
       "20970    We present a new approach for identifying si...                 1   \n",
       "20971    The sum of Log-normal variates is encountere...                 0   \n",
       "20972    Recently, optional stopping has been a subje...                 0   \n",
       "\n",
       "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "ID                                                              \n",
       "1            0            0           0                     0   \n",
       "2            0            0           0                     0   \n",
       "3            0            1           0                     0   \n",
       "4            0            1           0                     0   \n",
       "5            0            0           1                     0   \n",
       "...        ...          ...         ...                   ...   \n",
       "20968        1            0           0                     0   \n",
       "20969        1            0           0                     0   \n",
       "20970        0            0           0                     0   \n",
       "20971        0            1           1                     0   \n",
       "20972        0            1           1                     0   \n",
       "\n",
       "       Quantitative Finance  \n",
       "ID                           \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "5                         0  \n",
       "...                     ...  \n",
       "20968                     0  \n",
       "20969                     0  \n",
       "20970                     0  \n",
       "20971                     0  \n",
       "20972                     0  \n",
       "\n",
       "[20972 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/JanataHack.csv', index_col='ID')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"TITLE\": \"title\", \"ABSTRACT\" : \"abstract\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for the categories\n",
    "categories = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_category_as_single_column(df):\n",
    "    df['category'] = df[categories[0]].astype(str) + df[categories[1]].astype(str) + df[categories[2]].astype(str) + df[categories[3]].astype(str) + df[categories[4]].astype(str) + df[categories[5]].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20968</th>\n",
       "      <td>Contemporary machine learning: a guide for pra...</td>\n",
       "      <td>Machine learning is finding increasingly bro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20969</th>\n",
       "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
       "      <td>Polycrystalline diamond coatings have been g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20970</th>\n",
       "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
       "      <td>We present a new approach for identifying si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971</th>\n",
       "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
       "      <td>The sum of Log-normal variates is encountere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>Why optional stopping is a problem for Bayesians</td>\n",
       "      <td>Recently, optional stopping has been a subje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>001100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20972 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "ID                                                         \n",
       "1            Reconstructing Subject-Specific Effect Maps   \n",
       "2                     Rotation Invariance Neural Network   \n",
       "3      Spherical polyharmonics and Poisson kernels fo...   \n",
       "4      A finite element approximation for the stochas...   \n",
       "5      Comparative study of Discrete Wavelet Transfor...   \n",
       "...                                                  ...   \n",
       "20968  Contemporary machine learning: a guide for pra...   \n",
       "20969  Uniform diamond coatings on WC-Co hard alloy c...   \n",
       "20970  Analysing Soccer Games with Clustering and Con...   \n",
       "20971  On the Efficient Simulation of the Left-Tail o...   \n",
       "20972   Why optional stopping is a problem for Bayesians   \n",
       "\n",
       "                                                abstract  Computer Science  \\\n",
       "ID                                                                           \n",
       "1        Predictive models allow subject-specific inf...                 1   \n",
       "2        Rotation invariance and translation invarian...                 1   \n",
       "3        We introduce and develop the notion of spher...                 0   \n",
       "4        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "5        Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "...                                                  ...               ...   \n",
       "20968    Machine learning is finding increasingly bro...                 1   \n",
       "20969    Polycrystalline diamond coatings have been g...                 0   \n",
       "20970    We present a new approach for identifying si...                 1   \n",
       "20971    The sum of Log-normal variates is encountere...                 0   \n",
       "20972    Recently, optional stopping has been a subje...                 0   \n",
       "\n",
       "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "ID                                                              \n",
       "1            0            0           0                     0   \n",
       "2            0            0           0                     0   \n",
       "3            0            1           0                     0   \n",
       "4            0            1           0                     0   \n",
       "5            0            0           1                     0   \n",
       "...        ...          ...         ...                   ...   \n",
       "20968        1            0           0                     0   \n",
       "20969        1            0           0                     0   \n",
       "20970        0            0           0                     0   \n",
       "20971        0            1           1                     0   \n",
       "20972        0            1           1                     0   \n",
       "\n",
       "       Quantitative Finance category  \n",
       "ID                                    \n",
       "1                         0   100000  \n",
       "2                         0   100000  \n",
       "3                         0   001000  \n",
       "4                         0   001000  \n",
       "5                         0   100100  \n",
       "...                     ...      ...  \n",
       "20968                     0   110000  \n",
       "20969                     0   010000  \n",
       "20970                     0   100000  \n",
       "20971                     0   001100  \n",
       "20972                     0   001100  \n",
       "\n",
       "[20972 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = add_category_as_single_column(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100000' '001000' '100100' '010000' '000010' '000100' '011000' '001100'\n",
      " '101000' '000001' '110000' '101100' '010100' '110100' '100010' '000110'\n",
      " '000101' '011100' '100001' '000011' '100110' '111000' '100101' '001101']\n",
      "Length of unique categories: 24\n"
     ]
    }
   ],
   "source": [
    "labels = df['category'].unique()\n",
    "print(labels)\n",
    "print(f'Length of unique categories: {len(labels)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to do some cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOPWORDS = set(get_stop_words('english'))\n",
    "\n",
    "def text_cleaning(text):\n",
    "    # transform to lowercase for later use of 'stopwords'\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove numbers\n",
    "    text = re.sub(r'\\w*\\d+\\w*', '', text)\n",
    "\n",
    "    # remove formulas\n",
    "    text = re.sub(r'\\$[^$$]*\\$', '', text)\n",
    "\n",
    "    # remove stop words\n",
    "    #text = ' '.join([word for word in text.split(' ') if word not in STOPWORDS])\n",
    "\n",
    "    # remove symbols\n",
    "    text = re.compile('[/(){}\\[\\]\\|@,;~]').sub(' ', text)\n",
    "\n",
    "    # replace over spaces\n",
    "    text = re.sub('\\s{2,}', \" \", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract_cleaned'] = df['abstract'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_wrapper(word):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Apply Classification Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the train and test data for the classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.abstract_cleaned\n",
    "y = df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and test data from dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naives Bayes Classifier\n",
    "description: https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/share/virtualenvs/data_science-dDCtDHdq/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_nb = Pipeline([('vect', CountVectorizer(stop_words = \"english\",preprocessor=stem_wrapper)), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "pipe_nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of naives bayes classifier 0.601907032181168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      000001       0.00      0.00      0.00        37\n",
      "      000010       0.00      0.00      0.00        87\n",
      "      000011       0.00      0.00      0.00         2\n",
      "      000100       0.00      0.00      0.00       331\n",
      "      000101       0.00      0.00      0.00         2\n",
      "      000110       0.00      0.00      0.00        23\n",
      "      001000       0.83      0.85      0.84       731\n",
      "      001100       0.00      0.00      0.00       172\n",
      "      010000       0.84      0.93      0.88      1044\n",
      "      010100       0.00      0.00      0.00        16\n",
      "      011000       0.00      0.00      0.00        62\n",
      "      011100       0.00      0.00      0.00         2\n",
      "      100000       0.41      0.96      0.57       956\n",
      "      100010       0.00      0.00      0.00         5\n",
      "      100100       0.55      0.04      0.07       453\n",
      "      100101       0.00      0.00      0.00         1\n",
      "      100110       0.00      0.00      0.00         1\n",
      "      101000       0.00      0.00      0.00       136\n",
      "      101100       0.00      0.00      0.00        33\n",
      "      110000       0.00      0.00      0.00        93\n",
      "      110100       0.00      0.00      0.00         5\n",
      "      111000       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.60      4195\n",
      "   macro avg       0.12      0.13      0.11      4195\n",
      "weighted avg       0.50      0.60      0.50      4195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print(f'accuracy of naives bayes classifier {accuracy_score(y_pred, y_test)}')\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine\n",
    "description: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/share/virtualenvs/data_science-dDCtDHdq/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_svm = Pipeline([('vect', CountVectorizer(stop_words = \"english\", preprocessor=stem_wrapper)), ('tfidf', TfidfTransformer()), ('svc', SVC(kernel=\"linear\", degree = 3))])\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of linear SVM classifier 0.6924910607866508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      000001       0.62      0.54      0.58        37\n",
      "      000010       0.50      0.37      0.42        87\n",
      "      000011       0.00      0.00      0.00         2\n",
      "      000100       0.37      0.29      0.33       331\n",
      "      000101       0.00      0.00      0.00         2\n",
      "      000110       0.00      0.00      0.00        23\n",
      "      001000       0.81      0.89      0.85       731\n",
      "      001100       0.65      0.59      0.62       172\n",
      "      010000       0.87      0.93      0.90      1044\n",
      "      010100       0.00      0.00      0.00        16\n",
      "      011000       0.67      0.03      0.06        62\n",
      "      011100       0.00      0.00      0.00         2\n",
      "      100000       0.63      0.82      0.71       956\n",
      "      100010       0.00      0.00      0.00         5\n",
      "      100100       0.48      0.51      0.49       453\n",
      "      100101       0.00      0.00      0.00         1\n",
      "      100110       0.00      0.00      0.00         1\n",
      "      101000       0.39      0.05      0.09       136\n",
      "      101100       0.00      0.00      0.00        33\n",
      "      110000       0.50      0.08      0.13        93\n",
      "      110100       0.00      0.00      0.00         5\n",
      "      111000       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.69      4195\n",
      "   macro avg       0.30      0.23      0.24      4195\n",
      "weighted avg       0.66      0.69      0.66      4195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print(f'accuracy of linear SVM classifier {accuracy_score(y_pred, y_test)}')\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/share/virtualenvs/data_science-dDCtDHdq/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_rfc = Pipeline([('vect', CountVectorizer(stop_words = \"english\", preprocessor=stem_wrapper)), ('tfidf', TfidfTransformer()), ('clf', KNeighborsClassifier())])\n",
    "pipe_rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of k nearest neighbour classifier 0.6195470798569725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      000001       0.44      0.51      0.48        37\n",
      "      000010       0.40      0.33      0.36        87\n",
      "      000011       0.00      0.00      0.00         2\n",
      "      000100       0.30      0.36      0.32       331\n",
      "      000101       0.00      0.00      0.00         2\n",
      "      000110       0.23      0.13      0.17        23\n",
      "      001000       0.73      0.84      0.78       731\n",
      "      001100       0.45      0.41      0.43       172\n",
      "      010000       0.84      0.84      0.84      1044\n",
      "      010100       0.33      0.06      0.11        16\n",
      "      011000       0.44      0.06      0.11        62\n",
      "      011100       0.00      0.00      0.00         2\n",
      "      100000       0.60      0.71      0.65       956\n",
      "      100010       0.00      0.00      0.00         5\n",
      "      100100       0.42      0.38      0.40       453\n",
      "      100101       0.00      0.00      0.00         1\n",
      "      100110       0.00      0.00      0.00         1\n",
      "      101000       0.29      0.07      0.11       136\n",
      "      101100       0.00      0.00      0.00        33\n",
      "      110000       0.30      0.06      0.11        93\n",
      "      110100       0.00      0.00      0.00         5\n",
      "      111000       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62      4195\n",
      "   macro avg       0.26      0.22      0.22      4195\n",
      "weighted avg       0.59      0.62      0.60      4195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print(f'accuracy of k nearest neighbour classifier {accuracy_score(y_pred, y_test)}')\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science-dDCtDHdq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "879e0aa37acc94d6458fa173f3288bcea56e82a3b9fca582a9c7d294b714e537"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
